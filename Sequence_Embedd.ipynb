{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/Master MVA/ALTEGRAD/Data Challenge ALTEGRAD/Files/graph_labels.txt\" ./\n",
        "#!cp \"/content/drive/MyDrive/Master MVA/ALTEGRAD/Data Challenge ALTEGRAD/Files/edge_attributes.txt\" ./\n",
        "#!cp \"/content/drive/MyDrive/Master MVA/ALTEGRAD/Data Challenge ALTEGRAD/Files/edgelist.txt\" ./\n",
        "#!cp \"/content/drive/MyDrive/Master MVA/ALTEGRAD/Data Challenge ALTEGRAD/Files/graph_indicator.txt\" ./\n",
        "#!cp \"/content/drive/MyDrive/Master MVA/ALTEGRAD/Data Challenge ALTEGRAD/Files/node_attributes.txt\" ./\n",
        "!cp \"/content/drive/MyDrive/Master MVA/ALTEGRAD/Data Challenge ALTEGRAD/Files/sequences.txt\" ./"
      ],
      "metadata": {
        "id": "GONIkfJEHKi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Opção treinar do zero \n",
        "#https://www.kaggle.com/code/danofer/deep-protein-sequence-family-classification"
      ],
      "metadata": {
        "id": "KFKHGx3t8P_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -U pip > /dev/null\n",
        "!pip3 install -U bio_embeddings[all] > /dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0og6LpXgTeA",
        "outputId": "d090ea9e-c19b-4961-9cd8-c811c5fb562d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.14.1+cu116 requires torch==1.13.1, but you have torch 1.9.1 which is incompatible.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.9.1 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.9.1 which is incompatible.\n",
            "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 2.3.9 which is incompatible.\n",
            "confection 0.0.3 requires srsly<3.0.0,>=2.4.0, but you have srsly 1.0.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bio-embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfWjvzd_Xc1q",
        "outputId": "ffeee0a5-edc1-48b8-ed0e-46727bab24d4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bio-embeddings in /usr/local/lib/python3.8/dist-packages (0.2.2)\n",
            "Requirement already satisfied: plotly<6.0.0,>=5.1.0 in /usr/local/lib/python3.8/dist-packages (from bio-embeddings) (5.5.0)\n",
            "Requirement already satisfied: gensim<4.0.0,>=3.8.2 in /usr/local/lib/python3.8/dist-packages (from bio-embeddings) (3.8.3)\n",
            "Requirement already satisfied: umap-learn<0.6.0,>=0.5.1 in /usr/local/lib/python3.8/dist-packages (from bio-embeddings) (0.5.3)\n",
            "Requirement already satisfied: ruamel.yaml<0.18.0,>=0.17.10 in /usr/local/lib/python3.8/dist-packages (from bio-embeddings) (0.17.21)\n",
            "Requirement already satisfied: scikit-learn<0.25.0,>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from bio-embeddings) (0.24.2)\n",
            "Requirement already satisfied: atomicwrites<2.0.0,>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from bio-embeddings) (1.4.1)\n",
            "Requirement already satisfied: h5py<4.0.0,>=3.2.1 in /usr/local/lib/python3.8/dist-packages (from bio-embeddings) (3.7.0)\n",
            "Requirement already satisfied: python-slugify<6.0.0,>=5.0.2 in /usr/local/lib/python3.8/dist-packages (from bio-embeddings) (5.0.2)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.4 in /usr/local/lib/python3.8/dist-packages (from bio-embeddings) (1.4.4)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from bio-embeddings) (1.3.5)\n",
            "Requirement already satisfied: torch<=1.10.0,>=1.8.0 in /usr/local/lib/python3.8/dist-packages (from bio-embeddings) (1.9.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.18.3 in /usr/local/lib/python3.8/dist-packages (from bio-embeddings) (1.21.6)\n",
            "Requirement already satisfied: biopython<2.0,>=1.79 in /usr/local/lib/python3.8/dist-packages (from bio-embeddings) (1.80)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.2.1 in /usr/local/lib/python3.8/dist-packages (from bio-embeddings) (3.2.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from bio-embeddings) (1.7.3)\n",
            "Requirement already satisfied: humanize<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from bio-embeddings) (3.14.0)\n",
            "Requirement already satisfied: lock<2019.0.0,>=2018.3.25 in /usr/local/lib/python3.8/dist-packages (from bio-embeddings) (2018.3.25.2110)\n",
            "Requirement already satisfied: importlib_metadata<5.0.0,>=4.6.1 in /usr/local/lib/python3.8/dist-packages (from bio-embeddings) (4.13.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.45.0 in /usr/local/lib/python3.8/dist-packages (from bio-embeddings) (4.64.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from gensim<4.0.0,>=3.8.2->bio-embeddings) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from gensim<4.0.0,>=3.8.2->bio-embeddings) (6.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib_metadata<5.0.0,>=4.6.1->bio-embeddings) (3.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.2.1->bio-embeddings) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.2.1->bio-embeddings) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.2.1->bio-embeddings) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.2.1->bio-embeddings) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<2.0.0,>=1.2.0->bio-embeddings) (2022.7)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly<6.0.0,>=5.1.0->bio-embeddings) (8.1.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify<6.0.0,>=5.0.2->bio-embeddings) (1.3)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /usr/local/lib/python3.8/dist-packages (from ruamel.yaml<0.18.0,>=0.17.10->bio-embeddings) (0.2.7)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<0.25.0,>=0.24.0->bio-embeddings) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<0.25.0,>=0.24.0->bio-embeddings) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch<=1.10.0,>=1.8.0->bio-embeddings) (4.4.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.8/dist-packages (from umap-learn<0.6.0,>=0.5.1->bio-embeddings) (0.5.8)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.8/dist-packages (from umap-learn<0.6.0,>=0.5.1->bio-embeddings) (0.56.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.49->umap-learn<0.6.0,>=0.5.1->bio-embeddings) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.49->umap-learn<0.6.0,>=0.5.1->bio-embeddings) (0.39.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "us3nGop_jItj"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Read sequences\n",
        "sequences = list()\n",
        "with open('sequences.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        sequences.append(line[:-1])\n",
        "\n",
        "# Split data into training and test sets\n",
        "sequences_train = list()\n",
        "sequences_test = list()\n",
        "proteins_test = list()\n",
        "y_train = list()\n",
        "with open('graph_labels.txt', 'r') as f:\n",
        "    for i,line in enumerate(f):\n",
        "        t = line.split(',')\n",
        "        if len(t[1][:-1]) == 0:\n",
        "            proteins_test.append(t[0])\n",
        "            sequences_test.append(sequences[i])\n",
        "        else:\n",
        "            sequences_train.append(sequences[i])\n",
        "            y_train.append(int(t[1][:-1]))\n",
        "\n",
        "# Map sequences to \n",
        "#vec = TfidfVectorizer(analyzer='char', ngram_range=(1, 3))\n",
        "#X_train_sequence = vec.fit_transform(sequences_train)\n",
        "#X_test_sequence = vec.transform(sequences_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bio_embeddings.embed import ProtTransBertBFDEmbedder\n",
        "embedder_model = ProtTransBertBFDEmbedder()\n",
        "batch_size = 16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "xhrVH4__gJCJ",
        "outputId": "4883f1b7-30c6-426e-ec9b-1424a0de5a0a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-29450513f9e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbio_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProtTransBertBFDEmbedder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0membedder_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProtTransBertBFDEmbedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'ProtTransBertBFDEmbedder' from 'bio_embeddings.embed' (/usr/local/lib/python3.8/dist-packages/bio_embeddings/embed/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "X_train_sequence = []\n",
        "\n",
        "for seq in tqdm(sequences_train):\n",
        "    # do something with x\n",
        "  #for i in range(0, len(sequences_train)):\n",
        "  #seq_batch = sequences_train[i]#:min(len(sequences_train), i+batch_size)]\n",
        "  embedding = embedder_model.embed(seq)\n",
        "  X_train_sequence.append(embedding)"
      ],
      "metadata": {
        "id": "pqLfEBKOiK7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_sequence[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bg3PLH5qppzb",
        "outputId": "7e8ae52e-ede1-4643-a5ad-1c164234a0c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.04346859,  0.09442946, -0.01711776, ...,  0.13002351,\n",
              "         0.03772632,  0.04799961],\n",
              "       [ 0.05976252, -0.08812496,  0.00829028, ...,  0.00465693,\n",
              "         0.00127334, -0.044973  ],\n",
              "       [-0.11730403, -0.05469667,  0.09317888, ...,  0.00811603,\n",
              "        -0.00057063,  0.02693714],\n",
              "       ...,\n",
              "       [ 0.05833338, -0.08616583,  0.01873964, ..., -0.03190076,\n",
              "        -0.03273055, -0.13629143],\n",
              "       [ 0.05115892, -0.03320181,  0.07323511, ..., -0.08184524,\n",
              "        -0.05324489, -0.05401745],\n",
              "       [ 0.2221749 , -0.04878725, -0.00125229, ...,  0.0156033 ,\n",
              "        -0.00231342, -0.07513644]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_sequence[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQDyyBQ-rWvx",
        "outputId": "95da2be9-3d7a-4d16-a4a6-4c46c716d251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(185, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = X_train_sequence[0]\n",
        "B = np.pad(A, ((0, 989 - len(X_train_sequence[0])), (0,0)), 'constant')\n",
        "B\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mL9G8-hjqRZ6",
        "outputId": "7dee41ed-c785-4528-87a2-6749d1e84e07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.04346859,  0.09442946, -0.01711776, ...,  0.13002351,\n",
              "         0.03772632,  0.04799961],\n",
              "       [ 0.05976252, -0.08812496,  0.00829028, ...,  0.00465693,\n",
              "         0.00127334, -0.044973  ],\n",
              "       [-0.11730403, -0.05469667,  0.09317888, ...,  0.00811603,\n",
              "        -0.00057063,  0.02693714],\n",
              "       ...,\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "B.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUCm0EfOrnEm",
        "outputId": "b80263cb-ba48-4528-925a-cc7c52970805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(989, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_sequence = []\n",
        "for seq in tqdm(sequences_test):\n",
        "  embedding = embedder_model.embed(seq)\n",
        "  X_test_sequence.append(embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iVt7KG5kG_1",
        "outputId": "c351613a-18f5-41a4-da0e-9bf7be2ee45a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1223/1223 [01:44<00:00, 11.66it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('X_train_sequence_ProtTransBertBFDEmbedder.pkl', 'wb') as f:\n",
        "    pickle.dump(X_train_sequence, f)"
      ],
      "metadata": {
        "id": "8mwxojGokU0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('X_test_sequence_ProtTransBertBFDEmbedder.pkl', 'wb') as f:\n",
        "    pickle.dump(X_test_sequence, f)"
      ],
      "metadata": {
        "id": "Uo8bYURRkjR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sizes = []\n",
        "for elem in sequences_train:\n",
        "  sizes.append(len(elem))\n",
        "sizes = np.array(sizes)\n",
        "\n",
        "print(np.mean(sizes))\n",
        "print(np.max(sizes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRipagcbI5A2",
        "outputId": "596618f4-a699-4c68-856e-13948ff71cde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "258.14279869067104\n",
            "989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.std(sizes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BlHuvveJRrc",
        "outputId": "8c34e229-011a-45e2-cc90-7fa9ead28932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "162.24346887570542"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences[1]"
      ],
      "metadata": {
        "id": "V3Cg2vZ8LGJv",
        "outputId": "2ea4f6c4-a66a-4809-d7cc-0014ef33c4b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'RTDCYGNVNRIDTTGASCKTAKPEGLSYCGVSASKKIAERDLQAMDRYKTIIKKVGEKLCVEPAVIAGIISRESHAGKVLKNGWGDRGNGFGLMQVDKRSHKPQGTWNGEVHITQGTTILINFIKTIQKKFPSWTKDQQLKGGISAYNAGAGNVRSYARMDIGTTHDDYANDVVARAQYYKQHGY'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq_dim = X_train_sequence.shape[1]"
      ],
      "metadata": {
        "id": "yhogThxrlqF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import time\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "\n",
        "def load_data(): \n",
        "    \"\"\"\n",
        "    Function that loads graphs\n",
        "    \"\"\"  \n",
        "    graph_indicator = np.loadtxt(\"graph_indicator.txt\", dtype=np.int64)\n",
        "    _,graph_size = np.unique(graph_indicator, return_counts=True)\n",
        "    \n",
        "    edges = np.loadtxt(\"edgelist.txt\", dtype=np.int64, delimiter=\",\")\n",
        "    edges_inv = np.vstack((edges[:,1], edges[:,0]))\n",
        "    edges = np.vstack((edges, edges_inv.T))\n",
        "    s = edges[:,0]*graph_indicator.size + edges[:,1]\n",
        "    idx_sort = np.argsort(s)\n",
        "    edges = edges[idx_sort,:]\n",
        "    edges,idx_unique =  np.unique(edges, axis=0, return_index=True)\n",
        "    A = sp.csr_matrix((np.ones(edges.shape[0]), (edges[:,0], edges[:,1])), shape=(graph_indicator.size, graph_indicator.size))\n",
        "    \n",
        "    x = np.loadtxt(\"node_attributes.txt\", delimiter=\",\")\n",
        "    edge_attr = np.loadtxt(\"edge_attributes.txt\", delimiter=\",\")\n",
        "    edge_attr = np.vstack((edge_attr,edge_attr))\n",
        "    edge_attr = edge_attr[idx_sort,:]\n",
        "    edge_attr = edge_attr[idx_unique,:]\n",
        "    \n",
        "    adj = []\n",
        "    features = []\n",
        "    edge_features = []\n",
        "    idx_n = 0\n",
        "    idx_m = 0\n",
        "    for i in range(graph_size.size):\n",
        "        adj.append(A[idx_n:idx_n+graph_size[i],idx_n:idx_n+graph_size[i]])\n",
        "        edge_features.append(edge_attr[idx_m:idx_m+adj[i].nnz,:])\n",
        "        features.append(x[idx_n:idx_n+graph_size[i],:])\n",
        "        idx_n += graph_size[i]\n",
        "        idx_m += adj[i].nnz\n",
        "\n",
        "    return adj, features, edge_features\n",
        "\n",
        "def normalize_adjacency(A):\n",
        "    \"\"\"\n",
        "    Function that normalizes an adjacency matrix\n",
        "    \"\"\"\n",
        "    n = A.shape[0]\n",
        "    A += sp.identity(n)\n",
        "    degs = A.dot(np.ones(n))\n",
        "    inv_degs = np.power(degs, -1)\n",
        "    D = sp.diags(inv_degs)\n",
        "    A_normalized = D.dot(A)\n",
        "\n",
        "    return A_normalized\n",
        "\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "    \"\"\"\n",
        "    Function that converts a Scipy sparse matrix to a sparse Torch tensor\n",
        "    \"\"\"\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape)\n",
        "\n",
        "\n",
        "class GNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple message passing model that consists of 2 message passing layers\n",
        "    and the sum aggregation function\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, input_seq_dim, hidden_dim, dropout, n_class):\n",
        "        super(GNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, n_class)\n",
        "        self.fc_seq1 = nn.Linear(input_seq_dim, 2*hidden_dim)\n",
        "        self.fc_seq2 = nn.Linear(2*hidden_dim, hidden_dim)\n",
        "        self.fc_out = nn.Linear(2*hidden_dim, hidden_dim)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x_in, adj, idx, seq):\n",
        "\n",
        "        #print(seq.shape)\n",
        "        # first message passing layer\n",
        "        x = self.fc1(x_in)\n",
        "        x = self.relu(torch.mm(adj, x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # second message passing layer\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(torch.mm(adj, x))\n",
        "        \n",
        "        # sum aggregator\n",
        "        idx = idx.unsqueeze(1).repeat(1, x.size(1))\n",
        "        out_g = torch.zeros(torch.max(idx)+1, x.size(1)).to(x_in.device)\n",
        "        out_g = out_g.scatter_add_(0, idx, x)\n",
        "        \n",
        "        # batch normalization layer\n",
        "        out_g = self.bn1(out_g)\n",
        "\n",
        "        # mlp to produce output\n",
        "        out_g = self.relu(self.fc3(out_g))\n",
        "        out_g = self.dropout(out_g)\n",
        "\n",
        "        # Processing of the sequence\n",
        "        out_seq = self.relu(self.fc_seq1(seq))\n",
        "        out_seq = self.dropout(out_seq)\n",
        "        out_seq = self.relu(self.fc_seq2(out_seq))\n",
        "\n",
        "        out_seq = self.bn2(out_seq)\n",
        "\n",
        "        #print(out_g.shape)\n",
        "        #print(out_seq.shape)\n",
        "\n",
        "        # Merging both\n",
        "        out = self.relu(self.fc_out(torch.cat((out_g, out_seq),1)))\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        #print(torch.cat((out_g, out_seq),1).shape)\n",
        "\n",
        "        # Produce logits\n",
        "        out = self.fc4(out)\n",
        "\n",
        "        return F.log_softmax(out, dim=1)\n"
      ],
      "metadata": {
        "id": "60d3fATyjray"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_model(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple message passing model that consists of 2 message passing layers\n",
        "    and the sum aggregation function\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, input_seq_dim, hidden_dim, dropout, n_class):\n",
        "        super(RNN_model, self).__init__()\n",
        "        self.rnn = nn.LSTM(input_size=1024, hidden_size=512, batch_first=True, bidirectional=False) \n",
        "        self.fc1 = nn.Linear(512, 256)\n",
        "        self.fc2 = nn.Linear(256, 64)\n",
        "        self.fc3 = nn.Linear(64, n_class)\n",
        "        self.bn = nn.BatchNorm1d(hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out, (h_n, c_n) = self.rnn(x)\n",
        "        #print(x.shape)\n",
        "        #print(out.shape)\n",
        "        #print(h_n.shape)\n",
        "        #print(c_n.shape)\n",
        "        #print(\"proximos\")\n",
        "\n",
        "        #out = self.relu(self.fc1(out[:,-1,:]))\n",
        "        #out = torch.cat((h_n[0], h_n[1]), dim=1)\n",
        "        #out = h_n[0]\n",
        "        out = out.sum(dim=1)\n",
        "        out = self.relu(self.fc1(out))\n",
        "        #print(out.shape)\n",
        "        out = self.relu(self.fc2(out))\n",
        "        #print(out.shape)\n",
        "        out = self.fc3(out)\n",
        "        #print(out.shape)\n",
        "\n",
        "        return F.log_softmax(out, dim=1)"
      ],
      "metadata": {
        "id": "4fCnhNLyvpQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CharCNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, input_seq_dim, hidden_dim, drop_p, n_classes):\n",
        "        super().__init__()\n",
        "        # params: \"n_\" means dimension\n",
        "        self.n_vocab = n_vocab     # number of unique words in vocabulary \n",
        "        self.hidden_dim = hidden_dim   # number of hidden nodes in LSTM\n",
        "        \n",
        "        #self.embedding = nn.Embedding(num_embeddings=n_vocab, embedding_dim=n_embed, padding_idx=0)\n",
        "        self.conv1 = nn.Sequential(nn.Conv1d(1024, 256, kernel_size=7, padding=0), nn.ReLU(),nn.MaxPool1d(3))\n",
        "        self.conv2 = nn.Sequential(nn.Conv1d(256, 256, kernel_size=7, padding=0), nn.ReLU(),nn.MaxPool1d(3))\n",
        "        self.conv3 = nn.Sequential(nn.Conv1d(256, 256, kernel_size=3, padding=0), nn.ReLU())\n",
        "        self.conv4 = nn.Sequential(nn.Conv1d(256, 256, kernel_size=3, padding=0), nn.ReLU(), nn.MaxPool1d(4))\n",
        "        self.fc1 = nn.Sequential(nn.Linear(256, hidden_dim), nn.Dropout(drop_p))\n",
        "        self.fc2 = nn.Sequential(nn.Linear(hidden_dim, hidden_dim), nn.Dropout(drop_p))\n",
        "        self.fc3 = nn.Linear(hidden_dim, n_classes)\n",
        "\n",
        "        self.dropout = nn.Dropout(drop_p)\n",
        "        \n",
        "        \n",
        "    def forward(self, input_embed):\n",
        "        #print(input_chars.shape)\n",
        "        #embed = self.embedding(input_chars)\n",
        "        #print(embed.shape)\n",
        "        input_embed = embed.transpose(1, 2)\n",
        "        output = self.conv1(embed)\n",
        "        #print(output.shape)\n",
        "        output = self.conv2(output)\n",
        "        #print(output.shape)\n",
        "        output = self.conv3(output)\n",
        "        #print(output.shape)\n",
        "        output = self.conv4(output)\n",
        "        #print(output.shape)\n",
        "\n",
        "        #output = output.view(output.size(0), -1)\n",
        "        output = output.mean(dim=-1)\n",
        "        output = self.fc1(output)\n",
        "        #print(output.shape)\n",
        "        output = self.fc2(output)\n",
        "        #print(output.shape)\n",
        "        output = self.fc3(output)\n",
        "        #print(output.shape)\n",
        "\n",
        "        return F.log_softmax(output, dim=1)"
      ],
      "metadata": {
        "id": "vW2YUKGXTeGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train_sequence, X_val_sequence, y_train, y_val = train_test_split(X_train_sequence, y_train, test_size=0.2, random_state=42, stratify=y_train)"
      ],
      "metadata": {
        "id": "j-CKUk_ev2Y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=1, min_delta=1, file_name=\"model.pt\"):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.min_validation_loss = np.inf\n",
        "        self.file_name = file_name\n",
        "\n",
        "    def early_stop(self, model, validation_loss):\n",
        "        if validation_loss < self.min_validation_loss:\n",
        "            self.min_validation_loss = validation_loss\n",
        "            self.counter = 0\n",
        "            print(f\"Saving best model at: '{self.file_name}'\")\n",
        "            torch.save(model.state_dict(), self.file_name)\n",
        "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        return False\n",
        "#early_stopper = EarlyStopper(patience=3, min_delta=10)\n",
        "#torch.save(model.state_dict(), 'best-model-parameters.pt') # official \n",
        "\n",
        "# To load\n",
        "#the_model = TheModelClass(*args, **kwargs)\n",
        "#the_model.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "id": "TGRp49c7wGkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "metadata": {
        "id": "UTWJ7b5txNw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize device\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "# Hyperparameters\n",
        "epochs = 100 #50\n",
        "batch_size = 64\n",
        "n_hidden = 64\n",
        "n_input = 86\n",
        "dropout = 0.2\n",
        "learning_rate = 1e-2 #0.001\n",
        "n_class = 18\n",
        "\n",
        "# Compute number of training and test samples\n",
        "N_train = len(X_train_sequence)\n",
        "N_val = len(X_val_sequence)\n",
        "#N_test = len(adj_test)\n",
        "\n",
        "# Initializes model and optimizer\n",
        "model = CharCNN(n_input, 0, n_hidden, dropout, n_class).to(device)\n",
        "\n",
        "optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=learning_rate)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "early_stopping = EarlyStopping(patience=5, min_delta=0.1, file_name=\"merged-model.pt\")\n",
        "\n",
        "# Train model\n",
        "for epoch in range(epochs):\n",
        "    t = time.time()\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    count = 0\n",
        "    # Iterate over the batches\n",
        "    for i in range(0, N_train, batch_size):\n",
        "        X_sequence_batch = list()\n",
        "        y_batch = list()\n",
        "        \n",
        "        # Create tensors\n",
        "        for j in range(i, min(N_train, i+batch_size)):\n",
        "            X_sequence_batch.append(torch.FloatTensor(X_train_sequence[j]))\n",
        "            y_batch.append(y_train[j])\n",
        "            \n",
        "        X_sequence_batch = pad_sequence(X_sequence_batch,batch_first=True).to(device)\n",
        "        y_batch = torch.LongTensor(y_batch).to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(X_sequence_batch)\n",
        "        loss = loss_function(output, y_batch)\n",
        "        train_loss += loss.item() * output.size(0)\n",
        "        count += output.size(0)\n",
        "        preds = output.max(1)[1].type_as(y_batch)\n",
        "        correct += torch.sum(preds.eq(y_batch).double())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    #if epoch % 5 == 0:\n",
        "    #print('Epoch: {:03d}'.format(epoch+1),\n",
        "    #      'loss_train: {:.4f}'.format(train_loss / count),\n",
        "    #      'acc_train: {:.4f}'.format(correct / count),\n",
        "    #      'time: {:.4f}s'.format(time.time() - t))\n",
        "    loss_train = train_loss / count\n",
        "    acc_train = correct / count\n",
        "    time_train = time.time() - t\n",
        "\n",
        "    # Validate\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    count = 0\n",
        "    # Iterate over the batches\n",
        "    for i in range(0, N_val, batch_size):\n",
        "        X_sequence_batch = list()\n",
        "        y_batch = list()\n",
        "        \n",
        "        # Create tensors\n",
        "        for j in range(i, min(N_val, i+batch_size)):\n",
        "            X_sequence_batch.append(torch.FloatTensor(X_val_sequence[j]))\n",
        "            y_batch.append(y_val[j])\n",
        "            \n",
        "        X_sequence_batch = pad_sequence(X_sequence_batch,batch_first=True).to(device)\n",
        "        y_batch = torch.LongTensor(y_batch).to(device)\n",
        "        \n",
        "        output = model(X_sequence_batch)\n",
        "        loss = loss_function(output, y_batch)\n",
        "        val_loss += loss.item() * output.size(0)\n",
        "        count += output.size(0)\n",
        "        preds = output.max(1)[1].type_as(y_batch)\n",
        "        correct += torch.sum(preds.eq(y_batch).double())\n",
        "\n",
        "    loss_val = val_loss / count\n",
        "    print('Epoch: {:03d}'.format(epoch+1),\n",
        "          'loss_train: {:.4f}'.format(loss_train),\n",
        "          'loss_val: {:.4f}'.format(loss_val),\n",
        "          'acc_train: {:.4f}'.format(acc_train),\n",
        "          'acc_val: {:.4f}'.format(correct / count),\n",
        "          'time_train: {:.4f}s'.format(time_train))\n",
        "    if early_stopping.early_stop(model, loss_val):\n",
        "      break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 954
        },
        "id": "kbm24tXJv_jS",
        "outputId": "c04b3c6b-23ba-4ed5-d967-54ec93141646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001 loss_train: 13.1231 loss_val: 2.6336 acc_train: 0.1808 acc_val: 0.2045 time_train: 19.1550s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 002 loss_train: 2.5409 loss_val: 2.4620 acc_train: 0.2041 acc_val: 0.2045 time_train: 19.1646s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 003 loss_train: 2.4256 loss_val: 2.3935 acc_train: 0.2041 acc_val: 0.2045 time_train: 18.2715s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 004 loss_train: 2.3815 loss_val: 2.3682 acc_train: 0.2041 acc_val: 0.2045 time_train: 18.2157s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 005 loss_train: 2.3651 loss_val: 2.3585 acc_train: 0.2041 acc_val: 0.2045 time_train: 18.4551s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 006 loss_train: 2.3585 loss_val: 2.3544 acc_train: 0.2041 acc_val: 0.2045 time_train: 18.4783s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 007 loss_train: 2.3557 loss_val: 2.3527 acc_train: 0.2041 acc_val: 0.2045 time_train: 18.3908s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 008 loss_train: 2.3544 loss_val: 2.3518 acc_train: 0.2041 acc_val: 0.2045 time_train: 18.3854s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 009 loss_train: 2.3538 loss_val: 2.3514 acc_train: 0.2041 acc_val: 0.2045 time_train: 19.3648s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 010 loss_train: 2.3535 loss_val: 2.3512 acc_train: 0.2041 acc_val: 0.2045 time_train: 18.3876s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 011 loss_train: 2.3534 loss_val: 2.3511 acc_train: 0.2041 acc_val: 0.2045 time_train: 18.4351s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 012 loss_train: 2.3533 loss_val: 2.3511 acc_train: 0.2041 acc_val: 0.2045 time_train: 18.8395s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 013 loss_train: 2.3533 loss_val: 2.3510 acc_train: 0.2041 acc_val: 0.2045 time_train: 18.3521s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 014 loss_train: 2.3532 loss_val: 2.3510 acc_train: 0.2041 acc_val: 0.2045 time_train: 18.3752s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 015 loss_train: 2.3532 loss_val: 2.3510 acc_train: 0.2041 acc_val: 0.2045 time_train: 18.3880s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 016 loss_train: 2.3532 loss_val: 2.3510 acc_train: 0.2015 acc_val: 0.2045 time_train: 18.3469s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 017 loss_train: 2.3532 loss_val: 2.3510 acc_train: 0.2013 acc_val: 0.2045 time_train: 18.3606s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 018 loss_train: 2.3533 loss_val: 2.3510 acc_train: 0.2013 acc_val: 0.2045 time_train: 18.3774s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 019 loss_train: 2.3533 loss_val: 2.3510 acc_train: 0.2013 acc_val: 0.2045 time_train: 18.4011s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 020 loss_train: 2.3533 loss_val: 2.3510 acc_train: 0.1992 acc_val: 0.2045 time_train: 18.3636s\n",
            "Saving best model at: 'merged-model.pt'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-550095308724>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mX_sequence_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sequence_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other stuff"
      ],
      "metadata": {
        "id": "jr5y-58XwAQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=1, min_delta=1, file_name=\"model.pt\"):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.min_validation_loss = np.inf\n",
        "        self.file_name = file_name\n",
        "\n",
        "    def early_stop(self, model, validation_loss):\n",
        "        if validation_loss < self.min_validation_loss:\n",
        "            self.min_validation_loss = validation_loss\n",
        "            self.counter = 0\n",
        "            print(f\"Saving best model at: '{self.file_name}'\")\n",
        "            torch.save(model.state_dict(), self.file_name)\n",
        "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        return False\n",
        "#early_stopper = EarlyStopper(patience=3, min_delta=10)\n",
        "#torch.save(model.state_dict(), 'best-model-parameters.pt') # official \n",
        "\n",
        "# To load\n",
        "#the_model = TheModelClass(*args, **kwargs)\n",
        "#the_model.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "id": "duhKztuTxz-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SequenceEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple message passing model that consists of 2 message passing layers\n",
        "    and the sum aggregation function\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, input_seq_dim, hidden_dim, dropout, n_class):\n",
        "        super(SequenceEncoder, self).__init__()\n",
        "        #self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        #self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        #self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        #self.fc4 = nn.Linear(hidden_dim, n_class)\n",
        "        self.fc_seq1 = nn.Linear(input_seq_dim, 2*hidden_dim)\n",
        "        self.fc_seq2 = nn.Linear(2*hidden_dim, hidden_dim)\n",
        "        self.fc_out = nn.Linear(hidden_dim, n_class)\n",
        "        self.bn = nn.BatchNorm1d(hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x_in, adj, idx, seq):\n",
        "\n",
        "        # Processing of the sequence\n",
        "        out_seq = self.relu(self.fc_seq1(seq))\n",
        "        out_seq = self.dropout(out_seq)\n",
        "        out_seq = self.relu(self.fc_seq2(out_seq))\n",
        "\n",
        "        out_seq = self.bn(out_seq)\n",
        "\n",
        "        # Merging both\n",
        "        out = self.fc_out(out_seq)\n",
        "\n",
        "        return F.log_softmax(out, dim=1)"
      ],
      "metadata": {
        "id": "YcVSL3wA0NcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GNNSimple(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple message passing model that consists of 2 message passing layers\n",
        "    and the sum aggregation function\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, input_seq_dim, hidden_dim, dropout, n_class):\n",
        "        super(GNNSimple, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, n_class)\n",
        "        self.bn = nn.BatchNorm1d(hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x_in, adj, idx, seq):\n",
        "        # first message passing layer\n",
        "        x = self.fc1(x_in)\n",
        "        x = self.relu(torch.mm(adj, x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # second message passing layer\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(torch.mm(adj, x))\n",
        "        \n",
        "        # sum aggregator\n",
        "        idx = idx.unsqueeze(1).repeat(1, x.size(1))\n",
        "        out = torch.zeros(torch.max(idx)+1, x.size(1)).to(x_in.device)\n",
        "        out = out.scatter_add_(0, idx, x)\n",
        "        \n",
        "        # batch normalization layer\n",
        "        out = self.bn(out)\n",
        "\n",
        "        # mlp to produce output\n",
        "        out = self.relu(self.fc3(out))\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc4(out)\n",
        "\n",
        "        return F.log_softmax(out, dim=1)"
      ],
      "metadata": {
        "id": "hUSJ4niNvbl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load graphs\n",
        "adj, features, edge_features = load_data()\n",
        "\n",
        "# Normalize adjacency matrices\n",
        "adj = [normalize_adjacency(A) for A in adj]\n",
        "\n",
        "# Split data into training and test sets\n",
        "adj_train = list()\n",
        "features_train = list()\n",
        "y_train = list()\n",
        "adj_test = list()\n",
        "features_test = list()\n",
        "proteins_test = list()\n",
        "with open('graph_labels.txt', 'r') as f:\n",
        "    for i,line in enumerate(f):\n",
        "        t = line.split(',')\n",
        "        if len(t[1][:-1]) == 0:\n",
        "            proteins_test.append(t[0])\n",
        "            adj_test.append(adj[i])\n",
        "            features_test.append(features[i])\n",
        "        else:\n",
        "            adj_train.append(adj[i])\n",
        "            features_train.append(features[i])\n",
        "            y_train.append(int(t[1][:-1]))"
      ],
      "metadata": {
        "id": "MhUXr3wXKp5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train_sequence, X_val_sequence, adj_train, adj_val, features_train, features_val, y_train, y_val = train_test_split(X_train_sequence, adj_train,features_train, y_train, test_size=0.2, random_state=42, stratify=y_train)"
      ],
      "metadata": {
        "id": "iQqHs0P1qXaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize device\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "# Hyperparameters\n",
        "epochs = 100 #50\n",
        "batch_size = 64\n",
        "n_hidden = 64\n",
        "n_input = 86\n",
        "dropout = 0.2\n",
        "learning_rate = 1e-4 #0.001\n",
        "n_class = 18\n",
        "\n",
        "# Compute number of training and test samples\n",
        "N_train = len(adj_train)\n",
        "N_val = len(adj_val)\n",
        "N_test = len(adj_test)\n",
        "\n",
        "# Initializes model and optimizer\n",
        "#model = GNNSimple(n_input, input_seq_dim, n_hidden, dropout, n_class).to(device)\n",
        "new_model = GNN(n_input, input_seq_dim, n_hidden, dropout, n_class)\n",
        "\n",
        "model = SequenceEncoder(n_input, input_seq_dim, n_hidden, dropout, n_class)\n",
        "model.load_state_dict(torch.load(\"sentence-encoder.pt\"))\n",
        "new_model.fc_seq1 = model.fc_seq1\n",
        "new_model.fc_seq2 = model.fc_seq2\n",
        "new_model.bn2 = model.bn\n",
        "\n",
        "model = GNNSimple(n_input, input_seq_dim, n_hidden, dropout, n_class)\n",
        "model.load_state_dict(torch.load(\"gnn-simple.pt\"))\n",
        "new_model.fc1 = model.fc1\n",
        "new_model.fc2 = model.fc2\n",
        "new_model.fc3 = model.fc3\n",
        "new_model.bn1 = model.bn\n",
        "\n",
        "model = new_model\n",
        "del new_model\n",
        "model = model.to(device)\n",
        "\n",
        "for n, p in model.named_parameters():\n",
        "  if 'fc1' in n or 'fc2' in n or 'fc3' in n or 'fc_seq1' in n or 'fc_seq2' in n:\n",
        "    p.requires_grad = False\n",
        "\n",
        "optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=learning_rate)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "early_stopping = EarlyStopping(patience=5, min_delta=0.1, file_name=\"merged-model.pt\")\n",
        "\n",
        "# Train model\n",
        "for epoch in range(epochs):\n",
        "    t = time.time()\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    count = 0\n",
        "    # Iterate over the batches\n",
        "    for i in range(0, N_train, batch_size):\n",
        "        adj_batch = list()\n",
        "        features_batch = list()\n",
        "        idx_batch = list()\n",
        "        y_batch = list()\n",
        "        X_sequence_batch = list()\n",
        "        \n",
        "        # Create tensors\n",
        "        for j in range(i, min(N_train, i+batch_size)):\n",
        "            n = adj_train[j].shape[0]\n",
        "            adj_batch.append(adj_train[j]+sp.identity(n))\n",
        "            features_batch.append(features_train[j])\n",
        "            idx_batch.extend([j-i]*n)\n",
        "            y_batch.append(y_train[j])\n",
        "            X_sequence_batch.append(X_train_sequence[j, :])\n",
        "            \n",
        "        adj_batch = sp.block_diag(adj_batch)\n",
        "        features_batch = np.vstack(features_batch)\n",
        "        X_sequence_batch = sp.vstack(X_sequence_batch)\n",
        "\n",
        "        adj_batch = sparse_mx_to_torch_sparse_tensor(adj_batch).to(device)\n",
        "        features_batch = torch.FloatTensor(features_batch).to(device)\n",
        "        idx_batch = torch.LongTensor(idx_batch).to(device)\n",
        "        y_batch = torch.LongTensor(y_batch).to(device)\n",
        "        X_sequence_batch = sparse_mx_to_torch_sparse_tensor(X_sequence_batch).to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(features_batch, adj_batch, idx_batch, X_sequence_batch)\n",
        "        loss = loss_function(output, y_batch)\n",
        "        train_loss += loss.item() * output.size(0)\n",
        "        count += output.size(0)\n",
        "        preds = output.max(1)[1].type_as(y_batch)\n",
        "        correct += torch.sum(preds.eq(y_batch).double())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    #if epoch % 5 == 0:\n",
        "    #print('Epoch: {:03d}'.format(epoch+1),\n",
        "    #      'loss_train: {:.4f}'.format(train_loss / count),\n",
        "    #      'acc_train: {:.4f}'.format(correct / count),\n",
        "    #      'time: {:.4f}s'.format(time.time() - t))\n",
        "    loss_train = train_loss / count\n",
        "    acc_train = correct / count\n",
        "    time_train = time.time() - t\n",
        "\n",
        "    # Validate\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    count = 0\n",
        "    # Iterate over the batches\n",
        "    for i in range(0, N_val, batch_size):\n",
        "        adj_batch = list()\n",
        "        features_batch = list()\n",
        "        idx_batch = list()\n",
        "        y_batch = list()\n",
        "        X_sequence_batch = list()\n",
        "        \n",
        "        # Create tensors\n",
        "        for j in range(i, min(N_val, i+batch_size)):\n",
        "            n = adj_val[j].shape[0]\n",
        "            adj_batch.append(adj_val[j]+sp.identity(n))\n",
        "            features_batch.append(features_val[j])\n",
        "            idx_batch.extend([j-i]*n)\n",
        "            y_batch.append(y_val[j])\n",
        "            X_sequence_batch.append(X_val_sequence[j, :])\n",
        "            \n",
        "        adj_batch = sp.block_diag(adj_batch)\n",
        "        features_batch = np.vstack(features_batch)\n",
        "        X_sequence_batch = sp.vstack(X_sequence_batch)\n",
        "\n",
        "        adj_batch = sparse_mx_to_torch_sparse_tensor(adj_batch).to(device)\n",
        "        features_batch = torch.FloatTensor(features_batch).to(device)\n",
        "        idx_batch = torch.LongTensor(idx_batch).to(device)\n",
        "        y_batch = torch.LongTensor(y_batch).to(device)\n",
        "        X_sequence_batch = sparse_mx_to_torch_sparse_tensor(X_sequence_batch).to(device)\n",
        "        \n",
        "        output = model(features_batch, adj_batch, idx_batch, X_sequence_batch)\n",
        "        loss = loss_function(output, y_batch)\n",
        "        val_loss += loss.item() * output.size(0)\n",
        "        count += output.size(0)\n",
        "        preds = output.max(1)[1].type_as(y_batch)\n",
        "        correct += torch.sum(preds.eq(y_batch).double())\n",
        "\n",
        "    loss_val = val_loss / count\n",
        "    print('Epoch: {:03d}'.format(epoch+1),\n",
        "          'loss_train: {:.4f}'.format(loss_train),\n",
        "          'loss_val: {:.4f}'.format(loss_val),\n",
        "          'acc_train: {:.4f}'.format(acc_train),\n",
        "          'acc_val: {:.4f}'.format(correct / count),\n",
        "          'time_train: {:.4f}s'.format(time_train))\n",
        "    if early_stopping.early_stop(model, loss_val):\n",
        "      break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NFoRKoNogbk",
        "outputId": "7b3d320e-ef29-4892-95b3-39abbb2b2326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001 loss_train: 2.7279 loss_val: 2.6476 acc_train: 0.2481 acc_val: 0.3671 time_train: 5.4289s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 002 loss_train: 2.3622 loss_val: 2.3951 acc_train: 0.5798 acc_val: 0.4427 time_train: 5.7735s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 003 loss_train: 1.9609 loss_val: 2.1444 acc_train: 0.6706 acc_val: 0.4724 time_train: 4.6428s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 004 loss_train: 1.5791 loss_val: 1.9491 acc_train: 0.7182 acc_val: 0.4969 time_train: 4.7433s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 005 loss_train: 1.2859 loss_val: 1.8165 acc_train: 0.7481 acc_val: 0.5102 time_train: 4.7251s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 006 loss_train: 1.0594 loss_val: 1.7239 acc_train: 0.7939 acc_val: 0.5286 time_train: 4.7345s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 007 loss_train: 0.8902 loss_val: 1.6569 acc_train: 0.8330 acc_val: 0.5481 time_train: 5.7450s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 008 loss_train: 0.7546 loss_val: 1.6033 acc_train: 0.8609 acc_val: 0.5542 time_train: 4.7941s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 009 loss_train: 0.6420 loss_val: 1.5671 acc_train: 0.8908 acc_val: 0.5593 time_train: 4.7910s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 010 loss_train: 0.5530 loss_val: 1.5327 acc_train: 0.9090 acc_val: 0.5685 time_train: 4.7939s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 011 loss_train: 0.4781 loss_val: 1.5131 acc_train: 0.9223 acc_val: 0.5706 time_train: 4.7650s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 012 loss_train: 0.4201 loss_val: 1.4975 acc_train: 0.9373 acc_val: 0.5787 time_train: 4.7645s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 013 loss_train: 0.3656 loss_val: 1.4821 acc_train: 0.9532 acc_val: 0.5828 time_train: 4.7546s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 014 loss_train: 0.3213 loss_val: 1.4707 acc_train: 0.9581 acc_val: 0.5869 time_train: 4.8504s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 015 loss_train: 0.2834 loss_val: 1.4628 acc_train: 0.9657 acc_val: 0.5900 time_train: 4.7379s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 016 loss_train: 0.2471 loss_val: 1.4564 acc_train: 0.9747 acc_val: 0.5910 time_train: 4.7600s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 017 loss_train: 0.2241 loss_val: 1.4507 acc_train: 0.9788 acc_val: 0.5961 time_train: 4.6978s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 018 loss_train: 0.1970 loss_val: 1.4494 acc_train: 0.9826 acc_val: 0.5982 time_train: 4.6286s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 019 loss_train: 0.1764 loss_val: 1.4465 acc_train: 0.9870 acc_val: 0.6002 time_train: 4.7360s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 020 loss_train: 0.1541 loss_val: 1.4479 acc_train: 0.9903 acc_val: 0.5951 time_train: 4.6540s\n",
            "Epoch: 021 loss_train: 0.1392 loss_val: 1.4443 acc_train: 0.9923 acc_val: 0.5961 time_train: 4.6964s\n",
            "Saving best model at: 'merged-model.pt'\n",
            "Epoch: 022 loss_train: 0.1306 loss_val: 1.4485 acc_train: 0.9928 acc_val: 0.5971 time_train: 4.7530s\n",
            "Epoch: 023 loss_train: 0.1154 loss_val: 1.4470 acc_train: 0.9941 acc_val: 0.6043 time_train: 4.7104s\n",
            "Epoch: 024 loss_train: 0.1039 loss_val: 1.4476 acc_train: 0.9946 acc_val: 0.6012 time_train: 4.7870s\n",
            "Epoch: 025 loss_train: 0.0962 loss_val: 1.4505 acc_train: 0.9959 acc_val: 0.6033 time_train: 4.7431s\n",
            "Epoch: 026 loss_train: 0.0836 loss_val: 1.4578 acc_train: 0.9980 acc_val: 0.6002 time_train: 4.6940s\n",
            "Epoch: 027 loss_train: 0.0797 loss_val: 1.4606 acc_train: 0.9974 acc_val: 0.6012 time_train: 4.7220s\n",
            "Epoch: 028 loss_train: 0.0699 loss_val: 1.4627 acc_train: 0.9977 acc_val: 0.6063 time_train: 4.6107s\n",
            "Epoch: 029 loss_train: 0.0670 loss_val: 1.4628 acc_train: 0.9969 acc_val: 0.6012 time_train: 4.6355s\n",
            "Epoch: 030 loss_train: 0.0600 loss_val: 1.4704 acc_train: 0.9980 acc_val: 0.6043 time_train: 4.7140s\n",
            "Epoch: 031 loss_train: 0.0570 loss_val: 1.4683 acc_train: 0.9977 acc_val: 0.6012 time_train: 4.6107s\n",
            "Epoch: 032 loss_train: 0.0530 loss_val: 1.4771 acc_train: 0.9977 acc_val: 0.6033 time_train: 4.6653s\n",
            "Epoch: 033 loss_train: 0.0485 loss_val: 1.4839 acc_train: 0.9990 acc_val: 0.6074 time_train: 4.6853s\n",
            "Epoch: 034 loss_train: 0.0468 loss_val: 1.4839 acc_train: 0.9990 acc_val: 0.6074 time_train: 5.5981s\n",
            "Epoch: 035 loss_train: 0.0445 loss_val: 1.4932 acc_train: 0.9985 acc_val: 0.6084 time_train: 4.7646s\n",
            "Epoch: 036 loss_train: 0.0412 loss_val: 1.4872 acc_train: 0.9982 acc_val: 0.6063 time_train: 4.7096s\n",
            "Epoch: 037 loss_train: 0.0383 loss_val: 1.4947 acc_train: 0.9985 acc_val: 0.6053 time_train: 4.7080s\n",
            "Epoch: 038 loss_train: 0.0355 loss_val: 1.5002 acc_train: 0.9992 acc_val: 0.6084 time_train: 4.6797s\n",
            "Epoch: 039 loss_train: 0.0315 loss_val: 1.5055 acc_train: 0.9995 acc_val: 0.6094 time_train: 5.7181s\n",
            "Epoch: 040 loss_train: 0.0308 loss_val: 1.5140 acc_train: 0.9995 acc_val: 0.6074 time_train: 4.7095s\n",
            "Epoch: 041 loss_train: 0.0272 loss_val: 1.5172 acc_train: 0.9997 acc_val: 0.6053 time_train: 4.6141s\n",
            "Epoch: 042 loss_train: 0.0270 loss_val: 1.5218 acc_train: 0.9992 acc_val: 0.6104 time_train: 4.6594s\n",
            "Epoch: 043 loss_train: 0.0282 loss_val: 1.5221 acc_train: 0.9985 acc_val: 0.6084 time_train: 4.6364s\n",
            "Epoch: 044 loss_train: 0.0252 loss_val: 1.5301 acc_train: 0.9987 acc_val: 0.6074 time_train: 4.6207s\n",
            "Epoch: 045 loss_train: 0.0230 loss_val: 1.5390 acc_train: 0.9987 acc_val: 0.6074 time_train: 4.7252s\n",
            "Epoch: 046 loss_train: 0.0211 loss_val: 1.5439 acc_train: 0.9995 acc_val: 0.6115 time_train: 4.6427s\n",
            "Epoch: 047 loss_train: 0.0215 loss_val: 1.5472 acc_train: 0.9985 acc_val: 0.6094 time_train: 4.6339s\n",
            "Epoch: 048 loss_train: 0.0180 loss_val: 1.5603 acc_train: 1.0000 acc_val: 0.6125 time_train: 5.0186s\n",
            "Epoch: 049 loss_train: 0.0186 loss_val: 1.5577 acc_train: 0.9995 acc_val: 0.6084 time_train: 4.7969s\n",
            "Epoch: 050 loss_train: 0.0178 loss_val: 1.5713 acc_train: 1.0000 acc_val: 0.6084 time_train: 4.6957s\n",
            "Epoch: 051 loss_train: 0.0162 loss_val: 1.5659 acc_train: 0.9997 acc_val: 0.6084 time_train: 4.6717s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"merged-model.pt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOflT-ey7fYi",
        "outputId": "6ef735da-9a00-4b50-a310-94e08e234213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "model.eval()\n",
        "y_pred_proba = list()\n",
        "# Iterate over the batches\n",
        "for i in range(0, N_test, batch_size):\n",
        "    adj_batch = list()\n",
        "    idx_batch = list()\n",
        "    features_batch = list()\n",
        "    y_batch = list()\n",
        "    X_test_sequence_batch = list()\n",
        "    \n",
        "    # Create tensors\n",
        "    for j in range(i, min(N_test, i+batch_size)):\n",
        "        n = adj_test[j].shape[0]\n",
        "        adj_batch.append(adj_test[j]+sp.identity(n))\n",
        "        features_batch.append(features_test[j])\n",
        "        idx_batch.extend([j-i]*n)\n",
        "        X_test_sequence_batch.append(X_test_sequence[j, :])\n",
        "        \n",
        "    adj_batch = sp.block_diag(adj_batch)\n",
        "    features_batch = np.vstack(features_batch)\n",
        "    X_test_sequence_batch = sp.vstack(X_test_sequence_batch)\n",
        "\n",
        "    adj_batch = sparse_mx_to_torch_sparse_tensor(adj_batch).to(device)\n",
        "    features_batch = torch.FloatTensor(features_batch).to(device)\n",
        "    idx_batch = torch.LongTensor(idx_batch).to(device)\n",
        "    X_test_sequence_batch = sparse_mx_to_torch_sparse_tensor(X_test_sequence_batch).to(device)\n",
        "\n",
        "    output = model(features_batch, adj_batch, idx_batch, X_test_sequence_batch)\n",
        "    y_pred_proba.append(output)\n",
        "    \n",
        "y_pred_proba = torch.cat(y_pred_proba, dim=0)\n",
        "y_pred_proba = torch.exp(y_pred_proba)\n",
        "y_pred_proba = y_pred_proba.detach().cpu().numpy()\n",
        "\n",
        "# Write predictions to a file\n",
        "with open('sample_submission.csv', 'w') as csvfile:\n",
        "    writer = csv.writer(csvfile, delimiter=',')\n",
        "    lst = list()\n",
        "    for i in range(18):\n",
        "        lst.append('class'+str(i))\n",
        "    lst.insert(0, \"name\")\n",
        "    writer.writerow(lst)\n",
        "    for i, protein in enumerate(proteins_test):\n",
        "        lst = y_pred_proba[i,:].tolist()\n",
        "        lst.insert(0, protein)\n",
        "        writer.writerow(lst)"
      ],
      "metadata": {
        "id": "-MMYR3iqMKP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc1"
      ],
      "metadata": {
        "id": "N-3Nwi9YPZRt",
        "outputId": "641ec085-1f5f-4b56-8186-ee35d40fb5c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=86, out_features=64, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}